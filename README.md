# News Crawler Project

Dá»± Ã¡n thu tháº­p vÃ  phÃ¢n tÃ­ch tin tá»©c tá»± Ä‘á»™ng Ä‘Æ°á»£c chuyá»ƒn Ä‘á»•i tá»« Jupyter Notebook sang Python.

## TÃ­nh nÄƒng

### ğŸš€ News Crawler (`news_crawler.py`)
- **Chá»©c nÄƒng Ä‘áº§y Ä‘á»§**: Thu tháº­p tin tá»©c tá»« nhiá»u website
- **AI Summarization**: TÃ³m táº¯t bÃ i viáº¿t báº±ng Gemini AI
- **SEO Analysis**: PhÃ¢n tÃ­ch dá»¯ liá»‡u SEO
- **Auto Scheduling**: Cháº¡y tá»± Ä‘á»™ng theo lá»‹ch
- **Multi-domain**: Há»— trá»£ TechCrunch, VnExpress, TechRadar, VietnamNet

### ğŸ“° Simple Crawler (`simple_crawler.py`)
- **PhiÃªn báº£n Ä‘Æ¡n giáº£n**: Test vÃ  crawl nhanh
- **Local AI**: Sá»­ dá»¥ng Transformers Ä‘á»ƒ tÃ³m táº¯t
- **Batch Processing**: Xá»­ lÃ½ nhiá»u URL cÃ¹ng lÃºc
- **Export Data**: Xuáº¥t ra JSON vÃ  CSV

## CÃ i Ä‘áº·t

### 1. CÃ i Ä‘áº·t Python dependencies
```bash
pip install -r requirements.txt
```

### 2. CÃ i Ä‘áº·t Chrome Browser
- Táº£i vÃ  cÃ i Ä‘áº·t Google Chrome
- ChromeDriver sáº½ Ä‘Æ°á»£c tá»± Ä‘á»™ng táº£i vá»

## Sá»­ dá»¥ng

### News Crawler (PhiÃªn báº£n Ä‘áº§y Ä‘á»§)
```bash
python news_crawler.py
```

Chá»n chá»©c nÄƒng:
1. **Crawl tá»± Ä‘á»™ng theo lá»‹ch** - Cháº¡y liÃªn tá»¥c
2. **Crawl má»™t URL cá»¥ thá»ƒ** - Test má»™t link
3. **Crawl táº¥t cáº£ domain má»™t láº§n** - Thu tháº­p toÃ n bá»™
4. **Láº¥y thÃ´ng tin SEO tá»« URL** - PhÃ¢n tÃ­ch SEO

### Simple Crawler (PhiÃªn báº£n test)
```bash
python simple_crawler.py
```

Chá»n chá»©c nÄƒng:
1. **Crawl URLs máº«u** - Test vá»›i links cÃ³ sáºµn
2. **Crawl URL tÃ¹y chá»‰nh** - Nháº­p link muá»‘n crawl
3. **Crawl nhiá»u URLs tá»« file** - Xá»­ lÃ½ batch

## Cáº¥u hÃ¬nh

### Parser Configs (`parsers.json`)
```json
{
    "techcrunch": {
        "domain": "techcrunch.com",
        "title": "div.article-hero__middle",
        "content": "div.entry-content",
        "images": "div.entry-content img",
        "author": "a.wp-block-tc23-author-card-name__link",
        "time": "time",
        "topic": "div.tc23-post-relevant-terms__terms a",
        "references": "div.entry-content a"
    }
}
```

### Parser Links (`parsers_links.json`)
```json
{
    "techcrunch": {
        "domain": "techcrunch.com",
        "links": "a.loop-card__title-link"
    }
}
```

## Output Files

### Dá»¯ liá»‡u bÃ i viáº¿t
- `articles.json` - BÃ i viáº¿t chi tiáº¿t
- `articles_summarize.json` - BÃ i viáº¿t + tÃ³m táº¯t AI
- `seo_data.json` - Dá»¯ liá»‡u SEO

### Test files
- `test_article.json` - Káº¿t quáº£ test má»™t bÃ i
- `sample_articles.json` - Káº¿t quáº£ URLs máº«u
- `single_article.json` - Káº¿t quáº£ URL Ä‘Æ¡n láº»

## API Keys

### Gemini AI (cho news_crawler.py)
Cáº­p nháº­t `GEMINI_API_KEY` trong file `news_crawler.py`:
```python
self.GEMINI_API_KEY = "YOUR_API_KEY_HERE"
```

## Troubleshooting

### Lá»—i import
```bash
pip install selenium beautifulsoup4 webdriver-manager requests schedule pandas
```

### Lá»—i ChromeDriver
- Äáº£m báº£o Chrome Ä‘Ã£ Ä‘Æ°á»£c cÃ i Ä‘áº·t
- Kiá»ƒm tra káº¿t ná»‘i internet Ä‘á»ƒ táº£i ChromeDriver

### Lá»—i AI Model
```bash
pip install transformers torch
```

### Lá»—i Gemini API
- Kiá»ƒm tra API key
- Äáº£m báº£o cÃ³ quota API

## Cáº¥u trÃºc Files

```
Crawl Data - IEC/
â”œâ”€â”€ news_crawler.py          # Crawler Ä‘áº§y Ä‘á»§
â”œâ”€â”€ simple_crawler.py        # Crawler Ä‘Æ¡n giáº£n  
â”œâ”€â”€ requirements.txt         # Dependencies
â”œâ”€â”€ README.md               # Documentation
â”œâ”€â”€ parsers.json            # Cáº¥u hÃ¬nh parser (auto-generated)
â”œâ”€â”€ parsers_links.json      # Cáº¥u hÃ¬nh links (auto-generated)
â””â”€â”€ output files...         # JSON/CSV results
```

## TÃ­nh nÄƒng nÃ¢ng cao

### Láº­p lá»‹ch tá»± Ä‘á»™ng
- Crawl theo giá»/phÃºt
- LÆ°u log thá»i gian
- Xá»­ lÃ½ lá»—i tá»± Ä‘á»™ng

### SEO Analysis
- Meta title, description
- H1, H2 tags
- Internal/external links
- Word count

### AI Summarization
- Gemini API (online)
- Transformers (offline)
- Vietnamese support

## License

MIT License
